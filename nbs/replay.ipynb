{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prioritized Experience Replay\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Bernoulli, Uniform\n",
    "\n",
    "import numpy as np\n",
    "from torchtyping import TensorType"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prioritized Level Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PrioritizedReplayDistribution:\n",
    "    def __init__(\n",
    "        self,\n",
    "        rho: float = 0.1,\n",
    "        beta: float = 0.1, # the beta coefficient for the P_S distribution\n",
    "    ) -> None:\n",
    "        self.rho = rho\n",
    "        self.beta = beta\n",
    "    \n",
    "    def create(\n",
    "        self,\n",
    "        score_levels: TensorType[\"batch_size\", \"n_seen_levels\"],\n",
    "        last_count_levels: TensorType[\"batch_size\", \"n_seen_levels\"], # the last episode that the level was played,\n",
    "        last_episode: TensorType[\"batch_size\"] # the last episode of each batch\n",
    "    ) -> TensorType[\"batch_size\", \"n_seen_levels\"]:\n",
    "        \"\"\"Create a prioritized level distribution.\"\"\"\n",
    "        \n",
    "        # scoring level distribution\n",
    "        unnormalized_scores = torch.pow(\n",
    "            input=F.normalize(score_levels, dim=-1),\n",
    "            exponent=1/self.beta\n",
    "        )\n",
    "        score_dist = unnormalized_scores / unnormalized_scores.sum(dim=-1)[:, None]\n",
    "        \n",
    "        # staleness-awareness distribution\n",
    "        stale_scores = last_episode - last_count_levels\n",
    "        stale_dist = stale_scores / stale_scores.sum(dim=-1)\n",
    "        \n",
    "        prioritized_dist = (1 - self.rho) * score_dist + self.rho * stale_dist\n",
    "        \n",
    "        return prioritized_dist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
